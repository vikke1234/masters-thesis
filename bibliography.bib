@inproceedings{li2008image,
  title={Image demosaicing: A systematic survey},
  author={Li, Xin and Gunturk, Bahadir and Zhang, Lei},
  booktitle={Visual Communications and Image Processing 2008},
  volume={6822},
  pages={489--503},
  year={2008},
  organization={SPIE}
}
@article{burstPhotMobile,
author = {Hasinoff, Samuel W. and Sharlet, Dillon and Geiss, Ryan and Adams, Andrew and Barron, Jonathan T. and Kainz, Florian and Chen, Jiawen and Levoy, Marc},
title = {Burst photography for high dynamic range and low-light imaging on mobile cameras},
year = {2016},
issue_date = {November 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/2980179.2980254},
doi = {10.1145/2980179.2980254},
abstract = {Cell phone cameras have small apertures, which limits the number of photons they can gather, leading to noisy images in low light. They also have small sensor pixels, which limits the number of electrons each pixel can store, leading to limited dynamic range. We describe a computational photography pipeline that captures, aligns, and merges a burst of frames to reduce noise and increase dynamic range. Our system has several key features that help make it robust and efficient. First, we do not use bracketed exposures. Instead, we capture frames of constant exposure, which makes alignment more robust, and we set this exposure low enough to avoid blowing out highlights. The resulting merged image has clean shadows and high bit depth, allowing us to apply standard HDR tone mapping methods. Second, we begin from Bayer raw frames rather than the demosaicked RGB (or YUV) frames produced by hardware Image Signal Processors (ISPs) common on mobile platforms. This gives us more bits per pixel and allows us to circumvent the ISP's unwanted tone mapping and spatial denoising. Third, we use a novel FFT-based alignment algorithm and a hybrid 2D/3D Wiener filter to denoise and merge the frames in a burst. Our implementation is built atop Android's Camera2 API, which provides per-frame camera control and access to raw imagery, and is written in the Halide domain-specific language (DSL). It runs in 4 seconds on device (for a 12 Mpix image), requires no user intervention, and ships on several mass-produced cell phones.},
journal = {ACM Trans. Graph.},
month = dec,
articleno = {192},
numpages = {12},
keywords = {high dynamic range, computational photography}
}

  @article{scharstein2002taxonomy,
  title={A taxonomy and evaluation of dense two-frame stereo correspondence algorithms},
  author={Scharstein, Daniel and Szeliski, Richard},
  journal={International journal of computer vision},
  volume={47},
  pages={7--42},
  year={2002},
  publisher={Springer}
}
@inproceedings{van2012memory,
  title={Memory errors: The past, the present, and the future},
  author={Van der Veen, Victor and Dutt-Sharma, Nitish and Cavallaro, Lorenzo and Bos, Herbert},
  booktitle={Research in Attacks, Intrusions, and Defenses: 15th International Symposium, RAID 2012, Amsterdam, The Netherlands, September 12-14, 2012. Proceedings 15},
  pages={86--106},
  year={2012},
  organization={Springer}
}
@incollection{adams2010frankencamera,
  title={The Frankencamera: An experimental platform for computational photography},
  author={Adams, Andrew and Talvala, Eino-Ville and Park, Sung Hee and Jacobs, David E and Ajdin, Boris and Gelfand, Natasha and Dolson, Jennifer and Vaquero, Daniel and Baek, Jongmin and Tico, Marius and others},
  booktitle={ACM SIGGRAPH 2010 papers},
  pages={1--12},
  year={2010}
}


@unpublished{libcameraStack,
    author = {Laurent Pinchart},
    title = {Giving Linux a Camera Stack: libcamera's 3 Years Journey and Exciting Future},
    year = {2021},
    month = {11},
    URL = {https://www.youtube.com/watch?v=gOusavlAlOE}
}

@misc{raspberrypiTuningGuide,
    author = {Raspberry Pi},
    title = {Raspberry Pi Tuning Guide},
    howpublished = {https://datasheets.raspberrypi.com/camera/raspberry-pi-camera-guide.pdf},
    year = {2023},
    month = {Oct},
}

@article{CMOSReview,
title = {Review of CMOS image sensors},
journal = {Microelectronics Journal},
volume = {37},
number = {5},
pages = {433-451},
year = {2006},
issn = {1879-2391},
doi = {https://doi.org/10.1016/j.mejo.2005.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0026269205002764},
author = {M. Bigas and E. Cabruja and J. Forest and J. Salvi},
keywords = {CMOS image sensors, APS},
abstract = {The role of CMOS Image Sensors since their birth around the 1960s, has been changing a lot. Unlike the past, current CMOS Image Sensors are becoming competitive with regard to Charged Couple Device (CCD) technology. They offer many advantages with respect to CCD, such as lower power consumption, lower voltage operation, on-chip functionality and lower cost. Nevertheless, they are still too noisy and less sensitive than CCDs. Noise and sensitivity are the key-factors to compete with industrial and scientific CCDs. It must be pointed out also that there are several kinds of CMOS Image sensors, each of them to satisfy the huge demand in different areas, such as Digital photography, industrial vision, medical and space applications, electrostatic sensing, automotive, instrumentation and 3D vision systems. In the wake of that, a lot of research has been carried out, focusing on problems to be solved such as sensitivity, noise, power consumption, voltage operation, speed imaging and dynamic range. In this paper, CMOS Image Sensors are reviewed, providing information on the latest advances achieved, their applications, the new challenges and their limitations. In conclusion, the State-of-the-art of CMOS Image Sensors.}
}

@ARTICLE{ieeeCMOS,
  author={El Gamal, A. and Eltoukhy, H.},
  journal={IEEE Circuits and Devices Magazine},
  title={CMOS image sensors},
  year={2005},
  volume={21},
  number={3},
  pages={6-20},
  keywords={CMOS image sensors;Sensor arrays;Image sensors;Pixel;Optical arrays;CMOS technology;Circuits;Optical imaging;Image converters;Color},
  doi={10.1109/MCD.2005.1438751}}

@INPROCEEDINGS{cmosAlen,
  author={Lu≈°tica, Alen},
  booktitle={Proceedings ELMAR-2011},
  title={CCD and CMOS image sensors in new HD cameras},
  year={2011},
  volume={},
  number={},
  pages={133-136},
  keywords={Charge coupled devices;CMOS integrated circuits;Noise;CMOS image sensors;Cameras;Photonics;Image sensor;CCD;CMOS},
  doi={}}

@ARTICLE{experimentalCompPhot,
  author={Levoy, Marc},
  journal={IEEE Computer Graphics and Applications},
  title={Experimental Platforms for Computational Photography},
  year={2010},
  volume={30},
  number={5},
  pages={81-87},
  keywords={Cameras;Photography;Software;Sensors;Hardware;Computational modeling;computational photography;Frankencamera;programmable cameras;computer graphics;graphics and applications},
  doi={10.1109/MCG.2010.85}}

@article{yangDeepLearningSingle2019,
  title = {Deep {{Learning}} for {{Single Image Super-Resolution}}: {{A Brief Review}}},
  shorttitle = {Deep {{Learning}} for {{Single Image Super-Resolution}}},
  author = {Yang, Wenming and Zhang, Xuechen and Tian, Yapeng and Wang, Wei and Xue, Jing-Hao and Liao, Qingmin},
  year = {2019},
  month = dec,
  journal = {IEEE Transactions on Multimedia},
  volume = {21},
  number = {12},
  pages = {3106--3121},
  issn = {1941-0077},
  doi = {10.1109/TMM.2019.2919431},
  urldate = {2024-04-08},
  abstract = {Single image super-resolution (SISR) is a notoriously challenging ill-posed problem that aims to obtain a high-resolution output from one of its low-resolution versions. Recently, powerful deep learning algorithms have been applied to SISR and have achieved state-of-the-art performance. In this survey, we review representative deep learning-based SISR methods and group them into two categories according to their contributions to two essential aspects of SISR: The exploration of efficient neural network architectures for SISR and the development of effective optimization objectives for deep SISR learning. For each category, a baseline is first established, and several critical limitations of the baseline are summarized. Then, representative works on overcoming these limitations are presented based on their original content, as well as our critical exposition and analyses, and relevant comparisons are conducted from a variety of perspectives. Finally, we conclude this review with some current challenges and future trends in SISR that leverage deep learning algorithms.},
  keywords = {deep learning,Deep learning,Image reconstruction,Image resolution,Machine learning algorithms,neural networks,Neural networks,objective function,Single image super-resolution},
  file = {/home/viktorh/Zotero/storage/87E3QZEA/Yang et al. - 2019 - Deep Learning for Single Image Super-Resolution A.pdf;/home/viktorh/Zotero/storage/F3HLJNP6/8723565.html}
}
@article{delbracio2021mobile,
  title={Mobile computational photography: A tour},
  author={Delbracio, Mauricio and Kelly, Damien and Brown, Michael S and Milanfar, Peyman},
  journal={Annual review of vision science},
  volume={7},
  number={1},
  pages={571--604},
  year={2021},
  publisher={Annual Reviews}
}
  @article{hammond1981camera,
  title={The camera obscura: A chronicle.},
  author={Hammond, John H},
  journal={The camera obscura: A chronicle},
  year={1981}
}

@book{gernsheim1986concise,
  title={A concise history of photography},
  author={Gernsheim, Helmut},
  number={10},
  year={1986},
  publisher={Courier Corporation}
}

@article{meng2016numerical,
  title={Numerical simulations and analyses of temperature control loop heat pipe for space CCD camera},
  author={Meng, Qingliang and Yang, Tao and Li, Chunlin},
  journal={Journal of thermal science},
  volume={25},
  pages={402--409},
  year={2016},
  publisher={Springer}
}

@article{peterson2001works,
  title={How it works: The charged-coupled device, or CCD},
  author={Peterson, Courtney},
  journal={Journal of young investigators},
  volume={3},
  number={1},
  year={2001}
}
@article{kalaiselvi2017survey,
  title={Survey of using GPU CUDA programming model in medical image analysis},
  author={Kalaiselvi, T and Sriramakrishnan, P and Somasundaram, K},
  journal={Informatics in Medicine Unlocked},
  volume={9},
  pages={133--144},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{foster2013visagge,
  title={Visagge: Visible angle grid for glass environments},
  author={Foster, Paul and Sun, Zhenghong and Park, Jong Jin and Kuipers, Benjamin},
  booktitle={2013 IEEE International Conference on Robotics and Automation},
  pages={2213--2220},
  year={2013},
  organization={IEEE}
}

@article{henley23lidar,
author = {Connor Henley and Siddharth Somasundaram and Joseph Hollmann and Ramesh Raskar},
journal = {Opt. Express},
keywords = {3D printing; Laser beams; Laser sources; Photon counting; Point clouds; Single-photon avalanche diodes},
number = {4},
pages = {6370--6388},
publisher = {Optica Publishing Group},
title = {Detection and mapping of specular surfaces using multibounce LiDAR returns},
volume = {31},
month = {2},
year = {2023},
url = {https://opg.optica.org/oe/abstract.cfm?URI=oe-31-4-6370},
doi = {10.1364/OE.479900},
abstract = {We propose methods that use specular, multibounce LiDAR returns to detect and map specular surfaces that might be invisible to conventional LiDAR systems that rely on direct, single-scatter returns. We derive expressions that relate the time- and angle-of-arrival of these multibounce returns to scattering points on the specular surface, and then use these expressions to formulate techniques for retrieving specular surface geometry when the scene is scanned by a single beam or illuminated with a multi-beam flash. We also consider the special case of transparent specular surfaces, for which surface reflections can be mixed together with light that scatters off of objects lying behind the surface.},
}
@inproceedings{diosi2004advanced,
  title={Advanced sonar and laser range finder fusion for simultaneous localization and mapping},
  author={Diosi, Albert and Kleeman, Lindsay},
  booktitle={2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)(IEEE Cat. No. 04CH37566)},
  volume={2},
  pages={1854--1859},
  year={2004},
  organization={IEEE}
}
@article{adi2017distance,
  title={Distance measurement with a stereo camera},
  author={Adi, Kusworo and Widodo, Catur Edi},
  journal={Int. J. Innov. Res. Adv. Eng},
  volume={4},
  number={11},
  pages={24--27},
  year={2017}
}
@article{safir2022rgb,
  title={Rgb And Ycbcr Color Spaces, Standards And Conversions For Fpga Engineers},
  author={Safir, Peter},
  journal={Universum: technical sciences},
  number={10-5 (103)},
  pages={63--66},
  year={2022},
  publisher={Limited Liability Company {\guillemotleft}International Center for Science}
}
@ARTICLE{yang2007ycbcr,
  author={Yang, Yang and Yuhua, Peng and Zhaoguang, Liu},
  journal={IEEE Transactions on Consumer Electronics},
  title={A Fast Algorithm for YCbCr to RGB Conversion},
  year={2007},
  volume={53},
  number={4},
  pages={1490-1493},
  keywords={Table lookup;Digital signal processing;Embedded system;Chromium;Space technology;Image converters;Liquid crystal displays;Image quality;Video codecs;Educational institutions},
  doi={10.1109/TCE.2007.4429242}}

@article{davson2010human,
  title={Human eye},
  author={Davson, Hugh and Perkins, Edward S},
  journal={Encyclopdia Britannica},
  year={2010},
  publisher={Encyclop{\ae}dia Britannica, Inc}
}
@article{wallace1991jpeg,
  title={The JPEG still picture compression standard},
  author={Wallace, Gregory K},
  journal={Communications of the ACM},
  volume={34},
  number={4},
  pages={30--44},
  year={1991},
  publisher={AcM New York, NY, USA}
}
@article{itu1993digital,
  title={Digital Compression and Coding of Continuous-tone Still Images-Part 1: requirements and guidelines},
  author={ITU-T, T},
  journal={Recommendation},
  year={1993}
}
@article{kumar2010theory,
  title={A Theory Based on Conversion of RGB image to Gray image},
  author={Kumar, Tarun and Verma, Karun},
  journal={International Journal of Computer Applications},
  volume={7},
  number={2},
  pages={7--10},
  year={2010},
  publisher={Foundation of Computer Science}
}
@article{xu2011robust,
  title={Robust automatic focus algorithm for low contrast images using a new contrast measure},
  author={Xu, Xin and Wang, Yinglin and Tang, Jinshan and Zhang, Xiaolong and Liu, Xiaoming},
  journal={Sensors},
  volume={11},
  number={9},
  pages={8281--8294},
  year={2011},
  publisher={Molecular Diversity Preservation International (MDPI)}
}
@article{foster2011color,
  title={Color constancy},
  author={Foster, David H},
  journal={Vision research},
  volume={51},
  number={7},
  pages={674--700},
  year={2011},
  publisher={Elsevier}
}
@incollection{ebner2021color,
  title={Color constancy},
  author={Ebner, Marc},
  booktitle={Computer Vision: A Reference Guide},
  pages={168--175},
  year={2021},
  publisher={Springer}
}
@article{agarwal2006overview,
  title={An overview of color constancy algorithms},
  author={Agarwal, Vivek and Abidi, Besma R and Koschan, Andreas and Abidi, Mongi A},
  journal={Journal of Pattern Recognition Research},
  volume={1},
  number={1},
  pages={42--54},
  year={2006},
  publisher={Journal of Pattern Recognition Research}
}

@book{international1957international,
  title={International lighting vocabulary},
  author={International Commission on Illumination},
  volume={1},
  year={1957},
  publisher={CIE Bureau central}
}

@patent {pdafPatent,
  number={US9973678B2},
  nationality={United States},
  author={Emanuele, Mandelli and Gregory, Chow and Naveen, Kolli},
  title={Phase-detect autofocus}
}
@article{hasinoff2016burst,
  title={Burst photography for high dynamic range and low-light imaging on mobile cameras},
  author={Hasinoff, Samuel W and Sharlet, Dillon and Geiss, Ryan and Adams, Andrew and Barron, Jonathan T and Kainz, Florian and Chen, Jiawen and Levoy, Marc},
  journal={ACM Transactions on Graphics (ToG)},
  volume={35},
  number={6},
  pages={1--12},
  year={2016},
  publisher={ACM New York, NY, USA}
}
@article{yang2019deep,
  title={Deep learning for single image super-resolution: A brief review},
  author={Yang, Wenming and Zhang, Xuechen and Tian, Yapeng and Wang, Wei and Xue, Jing-Hao and Liao, Qingmin},
  journal={IEEE Transactions on Multimedia},
  volume={21},
  number={12},
  pages={3106--3121},
  year={2019},
  publisher={IEEE}
}
@article{chen2022real,
  title={Real-world single image super-resolution: A brief review},
  author={Chen, Honggang and He, Xiaohai and Qing, Linbo and Wu, Yuanyuan and Ren, Chao and Sheriff, Ray E and Zhu, Ce},
  journal={Information Fusion},
  volume={79},
  pages={124--145},
  year={2022},
  publisher={Elsevier}
}
  @inproceedings{rebecq2019events,
  title={Events-to-video: Bringing modern computer vision to event cameras},
  author={Rebecq, Henri and Ranftl, Ren{\'e} and Koltun, Vladlen and Scaramuzza, Davide},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3857--3866},
  year={2019}
}

@article{shariff2024event,
  title={Event Cameras in Automotive Sensing: A Review},
  author={Shariff, Waseem and Dilmaghani, Mehdi Sefidgar and Kielty, Paul and Moustafa, Mohamed and Lemley, Joe and Corcoran, Peter},
  journal={IEEE Access},
  year={2024},
  publisher={IEEE}
}

@article{wang2024research,
  title={Research, Applications and Prospects of Event-Based Pedestrian Detection: A Survey},
  author={Wang, Han and Nie, Yuman and Li, Yun and Liu, Hongjie and Liu, Min and Cheng, Wen and Wang, Yaoxiong},
  journal={arXiv preprint arXiv:2407.04277},
  year={2024}
}

  @INPROCEEDINGS{coilmotor2007,
  author={Hsu, Jhih-Da and Tsai, Ching-Lung and Tzou, Ying-Yu},
  booktitle={2007 IEEE Power Electronics Specialists Conference},
  title={Design and Implementation of a Voice-Coil Motor Servo Control IC for Auto-Focus Mobile Camera Applications},
  year={2007},
  volume={},
  number={},
  pages={1357-1362},
  keywords={Servomotors;Servosystems;Application specific integrated circuits;Cameras;Digital integrated circuits;Lenses;Servomechanisms;Digital control;Position control;Mobile handsets},
  doi={10.1109/PESC.2007.4342192}}

 @InProceedings{Abuolaim_2018_ECCV,
author = {Abuolaim, Abdullah and Punnappurath, Abhijith and Brown, Michael S.},
title = {Revisiting Autofocus for Smartphone Cameras},
booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}
