\chapter{Interviews}
In this section we'll cover the interviews we had. They will be covered in no
particular order. We will finish up with trends seen based on the interviews.
The questions were designed to try to get an overview of what the interviewee
thinks are problems in the field and what new things they would like to see.
The questions can be found below:

\begin{enumerate}
    \item What field are you in?
    \item What library do you use (libcamera, Argus, etc.) and why did you pick that?
    \item Did you compare other alternatives?
    \item Do you have any issues/annoyances with the current API that you'd like to highlight?
    \item Are there any features you'd like to see in the API?
    \item Do you think frame based APIs are preferable to a streaming based one where it would implicitly capture images for you?
    \item Have you heard of the camera standardization effort Kamaros? If so, do you have any thoughts on it?
    \item Are there any other inputs you'd like to give?
\end{enumerate}

\section{VR/AR}\label{section:interview:vrar}
When interviewing a senior engineer in the VR/AR field, he mentioned that
they use Genicam. He said they use the one provided by the manufacturer, this
is an easy way to get a sensor working. The main issue with these libraries
though is that the libraries are not always compatible with other manufacturers
libraries. Property naming for example is not always consistent, to the extent
of creating their own library just to manage these. The properties should be
standardized though they still make themselves incompatible with each other.

When asked if they thought they needed some new feature missing from the API,
the developer said that it already does everything he needed. While other
alternatives also exist, such as OpenCV\footnote{\href{https://opencv.org/}{OpenCV home page}}
and Halcon\footnote{\href{https://www.mvtec.com/products/halcon}{Halcon home page}}.
OpenCV does not have the specialized sensor support they need (they did not
mention what their needs were), and halcon is very expensive; this lead them to
choose Genicam. Genicam allowed them to do both frame based control, when
explicit settings were needed as well as a streaming one where performance was
required.

They did consider embedded cameras on Raspberry Pis, though the issue was cost
and size. The Raspberry Pis would have been too large and expensive for their
use case.

For their use case, they did not require the small size constrained environment
that the embedded camera APIs provided, allowing them to use the higher level
API like Genicam. Additionally they did not need the ISPs to be configured
much, disabling all autocontrol algorithms and setting a static exposure time.

For transporting the images, they used ethernet. While this is slower than
CSI-2, the distances for VR/AR glasses are too long. CSI-2 would corrupt the
image data, ethernet is a good compromise.

\section{Automotive}
Upon interviewing a team lead in the automotive industry, they mention that
they use a variety of different camera APIs: V4L2, media-ctl, HAL3, and some
proprietary ones like QCarCam. The APIs they use were largely not a choice, the
\textit{System On a Chip}s (SoC) they use provide a \textit{Board Support Package} (BSP).
If anything but the API that was provided by the BSP were to be used, it would
require tremendous effort. Because of this, the alternatives were not really
weighed.

They unlike the use case in \cref{section:interview:vrar}, automotive requires
more configuration of the camera. As mentioned in \cref{section:v4l2}, V4L2
doesn't provide means to configure the camera fully, at least not without
violating the API design. This means that proprietary extensions are required,
to cover what is missing. Though this does not fix all of the underlying issues
that they have with the API. For example having shared data stream access, V4L2
locks the device upon opening. V4L2 recommends that a userspace application is
made to forward the images\footnote{https://www.kernel.org/doc/html/v4.9/media/uapi/v4l/open.html\#shared-data-streams}
to each application in situations like this, though merely opening the device
does not grant exclusive access. Another issue they highlighted was error handling,
currently errors can be very abstract and it might not directly say what the
cause is.

They preferred the request based APIs where one always explicitly asks for a
new frame. Though they did mention that it was largely due to being used to
them. A streaming based one was potentially very interesting, due to possibility
of an easier use.

\section{Conclusions}
One clear issue in the field currently is that the manufacturers do not have a
standard way to configure cameras. This is something that makes it difficult
for the user to easily use different ones. While it may be beneficial to not
allow the user to configure the cameras of other manufacturers as they can't
move away as easily. This is a double edged sword, it also makes it difficult
for users to come try a product. This is something that should be rectified,
though it might be difficult to get all sensor vendors to agree on a single
standard.

\textbf{TODO}
